# ACE Playbook (Agentic Context Engineering)

A self-improving agent system for Claude Code that evolves execution heuristics through a **Generator → Reflector → Curator** meta-learning loop.

**Enhanced with:**
- Human-readable JSON5 format with inline comments
- Automatic markdown trace summaries
- Git integration with auto-commit/push
- Visual progress indicators and diffs
- Playbook analytics and performance tracking

## What is ACE?

ACE uses three specialized roles to continuously improve how Claude Code approaches tasks:

1. **Generator** - Executes tasks following current playbook heuristics, produces structured traces
2. **Reflector** - Analyzes traces to propose small, actionable improvements (deltas)
3. **Curator** - Merges deltas into the playbook with minimal, coherent edits

Unlike traditional prompt engineering (rewriting full prompts), ACE evolves a **playbook** of tactical bullets through incremental updates.

## Directory Structure

```
.claude/
├─ commands/
│  └─ ace.md                      # Main orchestrator (invoked via /ace)
└─ playbook/
   ├─ seed.playbook.json5         # Current playbook state (JSON5 format)
   ├─ prompts/
   │  ├─ generator.txt            # Generator role prompt template
   │  ├─ reflector.txt            # Reflector role prompt template
   │  └─ curator.txt              # Curator role prompt template
   ├─ utils/
   │  └─ json5_helper.py          # JSON5 parser/writer & trace formatting
   ├─ traces/                     # Saved execution traces
   │  ├─ trace_<timestamp>.json  # Machine-readable trace
   │  ├─ trace_<timestamp>.md    # Human-readable summary
   │  └─ .gitkeep
   └─ tasks.jsonl                 # Example task file for batch mode
```

## Playbook Format

The playbook (`.claude/playbook/seed.playbook.json5`) uses JSON5 format for human readability:

```json5
{
  // ACE Playbook - Evolving agent heuristics
  // Last updated: 2025-10-19T23:24:00Z

  "metadata": {
    "version": "1.0.0",
    "total_tasks_processed": 15,
    "created_at": "2025-10-19T23:24:00Z",
    "last_updated": "2025-10-19T23:24:00Z"
  },

  "bullets": [
    {
      "id": "B1",
      "text": "Clarify hard vs soft constraints before acting.",
      "helpful": 5,    // Proved helpful 5 times
      "harmful": 0,    // Caused issues 0 times
      "created_at": "2025-10-19T23:24:00Z",
      "last_triggered": "2025-10-19T14:32:11Z",
      "examples": []   // Evidence from traces
    },
    {
      "id": "B2",
      "text": "Prefer structured tool output over prose.",
      "helpful": 8,    // Proved helpful 8 times
      "harmful": 0,    // Caused issues 0 times
      "created_at": "2025-10-19T23:24:00Z",
      "last_triggered": "2025-10-19T14:35:22Z",
      "examples": []
    }
  ]
}
```

**Fields:**
- **id**: Stable identifier (never changes)
- **text**: The heuristic bullet (can be modified)
- **helpful/harmful**: Counters incremented based on observed utility
- **created_at**: When this bullet was added
- **last_triggered**: Last time this bullet was referenced
- **examples**: Array of trace IDs where this was particularly helpful
- **metadata**: Overall playbook stats and versioning

**Why JSON5?**
- Inline comments explain what counters mean
- More human-readable than pure JSON
- Still machine-parseable (via `.claude/playbook/utils/json5_helper.py`)

## New Features

### 1. Human-Readable Traces

Every task execution generates TWO trace files:

**Machine-readable** (`.json`):
```json
{
  "plan": "Implement email validation with regex",
  "actions": [{"step": 1, "what": "...", "tool": "Write", ...}],
  "bullets_referenced": ["B1", "B2"],
  "outcome": {"success": true, "answer_or_artifact": "..."}
}
```

**Human-readable** (`.md`):
```markdown
# ACE Trace Summary

**Task:** Implement email validation with regex
**Timestamp:** 2025-10-19T14:32:11Z

## Plan
Implement email validation using standard regex pattern...

## Execution Steps

### Step 1: Create validation function
- **Tool:** `Write`
- **Result:** Created email_validator.py with regex pattern

### Step 2: Add tests
...

## Outcome ✓
**Success:** true
**Result:** Email validator implemented with comprehensive test coverage
```

### 2. Git Integration

ACE automatically version controls your playbook evolution:

- Commits after each task with descriptive messages
- Includes trace files in commits
- Auto-pushes to remote (if configured)
- Graceful fallback if git unavailable

**Example commit message:**
```
ACE: Implement email validation with regex

- Added: 1 bullet (B6)
- Modified: 1 bullet (B2)
- Counters: B1 (+1), B2 (+1)
- Trace: trace_2025-10-19T14-32-11.json

Generated by ACE Orchestrator
```

### 3. Visual Progress Indicators

The orchestrator provides rich visual feedback:

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✓ Task 1/3 Completed: "Implement email validation"
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📊 Generator: Success
   • Referenced bullets: B1, B2, B4
   • Steps executed: 5

📝 Playbook Updates:
   + Added B6: "Validate input formats with regex patterns"
   ~ Modified B2: "Prefer typed outputs and structured validation"
   ↑ Counters: B1 (+1), B2 (+1), B4 (+1)

💾 Files:
   • Trace: .claude/playbook/traces/trace_2025-10-19T14-32-11.json
   • Summary: .claude/playbook/traces/trace_2025-10-19T14-32-11.md

📦 Git:
   ✓ Committed and pushed (abc1234)
```

**Legend:**
- `+` Added new bullet
- `~` Modified existing bullet
- `-` Deprecated/removed bullet
- `↑` Counter incremented
- `✓` Success
- `⚠` Warning

### 4. Playbook Analytics

The orchestrator tracks and displays:
- Total tasks processed
- Bullet performance rankings (by helpful counter)
- Recent additions and modifications
- Last triggered timestamps

## Setup

### Prerequisites

- Claude Code installed and configured
- Python 3.7+ (for JSON5 utilities)
- Git (optional, for version control features)

### Installation

1. **Copy ACE structure to your project:**
   ```bash
   # Clone or copy the .claude/ directory to your project
   cp -r .claude /path/to/your/project/
   ```

2. **Initialize git (if not already done):**
   ```bash
   cd /path/to/your/project
   git init
   git remote add origin <your-repo-url>
   ```

3. **Verify setup:**
   ```bash
   # Start Claude Code
   claude code

   # In Claude Code, test the ACE command
   > /ace "Test task: list files in current directory"
   ```

That's it! ACE will automatically:
- Parse the JSON5 playbook
- Execute tasks and generate traces
- Update the playbook with learnings
- Commit and push changes

## How to Use

### Single Task Mode

Execute one task with the current playbook:

```bash
claude code
> /ace "Implement a REST API endpoint for user authentication"
```

The orchestrator will:
1. Load current playbook
2. Spawn fresh Generator subagent to execute the task
3. Spawn Reflector to analyze the execution trace
4. Spawn Curator to merge proposed improvements
5. Update the playbook file

### Batch Mode

Process multiple tasks from a file:

```bash
> /ace batch .claude/playbook/tasks.jsonl
```

This runs the Generator → Reflector → Curator loop for each task in the file.

### Multi-Loop Training

Run multiple iterations over a task set to rapidly evolve the playbook:

```bash
> /ace batch .claude/playbook/tasks.jsonl --loops 5
```

This processes all tasks 5 times, accumulating improvements each iteration.

## Task File Format

Create a `.jsonl` file (JSON Lines) where each line is a task object:

```jsonl
{"task": "Create a Python function that validates email addresses", "context": "Use regex, handle edge cases"}
{"task": "Write a bash script that backs up a directory", "context": "Use tar.gz, timestamp the archive"}
```

- **task** (required): The task description
- **context** (optional): Additional constraints, tools, or environment details

## How the Loop Works

### 1. Generator Phase (Fresh Subagent)

- Receives: Current playbook + task description
- Executes: Task for real using all Claude Code tools (Read, Write, Edit, Bash, etc.)
- Outputs: Structured JSON trace:
  ```json
  {
    "plan": "high-level approach",
    "actions": [{"step": 1, "what": "...", "tool": "...", "result_summary": "..."}],
    "bullets_referenced": ["B1", "B3"],
    "outcome": {"success": true, "answer_or_artifact": "..."},
    "failures_or_frictions": ["encountered ambiguity in requirements"]
  }
  ```

### 2. Reflector Phase (Fresh Subagent)

- Receives: Trace + current playbook
- Analyzes: What went well, what could improve
- Outputs: Delta proposals:
  ```json
  {
    "deltas": [
      {
        "proposal_text": "Validate API schemas before making requests",
        "link_to_existing": "B2",
        "rationale": "Would have prevented the 400 error in step 3",
        "evidence_from_trace": "action step 3 failed due to missing field"
      }
    ],
    "counters": {
      "helpful": ["B1", "B2"],
      "harmful": []
    }
  }
  ```

### 3. Curator Phase (Fresh Subagent)

- Receives: Deltas + current playbook
- Merges: Proposes minimal, coherent updates
- Outputs: Update actions:
  ```json
  {
    "updates": [
      {"action": "modify", "target_id": "B2", "new_text": "Validate schemas and prefer typed outputs"},
      {"action": "add", "new_id": "B6", "text": "Log intermediate results for debugging"},
      {"action": "counters", "increments": {"helpful": ["B1", "B2"]}}
    ]
  }
  ```

### 4. Orchestrator Applies Updates

The main conductor (persistent Claude session) applies the Curator's updates:
- **modify**: Replace text for existing bullet
- **add**: Append new bullet with fresh ID
- **deprecate**: Remove outdated bullet
- **counters**: Increment helpful/harmful tallies

Writes updated playbook to `.claude/playbook/seed.playbook.json`.

## Why Fresh Subagents?

Each role (Generator/Reflector/Curator) is spawned as a **fresh subagent** via Claude Code's Task tool:

- **No context contamination**: Generator doesn't see Reflector's analysis, Curator doesn't see Generator's execution details
- **Objective evaluation**: Reflector analyzes traces without execution bias
- **Clean role separation**: Each agent focuses solely on its responsibility
- **Scalable**: Orchestrator can run hundreds of loops without context bloat

## Observability

### Dual-Format Traces

All Generator executions are saved in two formats:

**JSON traces** (`.claude/playbook/traces/trace_<timestamp>.json`):
- Machine-readable structured data
- Full action history with tool calls and results
- Bullets referenced during execution
- Outcome and failure data
- Perfect for automated analysis

**Markdown summaries** (`.claude/playbook/traces/trace_<timestamp>.md`):
- Human-readable narrative
- Step-by-step execution breakdown
- Visual indicators (✓/✗) for success/failure
- Quick review without parsing JSON
- Ideal for debugging and understanding

### What to Track

Use traces to:
- Review what the Generator actually did
- Debug failures or unexpected behavior
- Analyze which bullets were referenced
- Track evolution of playbook effectiveness over time
- Identify patterns in successful vs failed executions

### Git History

Since ACE commits after each task, you can:
```bash
# View playbook evolution
git log --oneline .claude/playbook/seed.playbook.json5

# See what changed in a specific task
git show abc1234

# Compare playbook across time
git diff HEAD~5 HEAD .claude/playbook/seed.playbook.json5
```

## Tips

### Start Small
Begin with 3-5 bullets and evolve gradually. Don't hand-craft a massive playbook upfront.

### Monitor Counters
Periodically review `helpful` vs `harmful` counts. Deprecate bullets with low utility.

### Prune Regularly
If the playbook grows beyond ~15 bullets, consider consolidating similar bullets or removing low-scoring ones.

### Task Diversity
For best results, use varied tasks that exercise different skills (API design, data processing, refactoring, etc.).

### Review Traces
Check `.claude/playbook/traces/` occasionally to understand what patterns emerge and where the Generator struggles.

## Example Workflow

```bash
# Terminal
$ cd my-project
$ claude code

# Inside Claude Code session
> /ace "Refactor the authentication module to use dependency injection"

# ACE orchestrator runs Generator → Reflector → Curator
# Playbook is updated with new insights

> /ace "Add comprehensive error handling to the API layer"

# Playbook continues evolving...

# Later, run batch training on a task suite
> /ace batch .claude/playbook/tasks.jsonl --loops 3

# Playbook has now learned from 9+ task executions
# Check the updated heuristics:
> cat .claude/playbook/seed.playbook.json
```

## Customization

### Modify Role Prompts

Edit `.claude/playbook/prompts/*.txt` to change how each role behaves:
- **generator.txt**: Add domain-specific constraints, tool preferences
- **reflector.txt**: Emphasize certain failure modes, adjust delta granularity
- **curator.txt**: Change merge logic, deduplication strategy

### Adjust Seed Playbook

Edit `.claude/playbook/seed.playbook.json` to include domain-specific heuristics for your project (e.g., "Always use async/await for database calls").

## How This Works with Claude Code

- The **orchestrator** (`/ace`) is a slash command that runs in your main Claude session
- It uses the **Task tool** to spawn subagents with completely fresh context
- Subagents have full tool access (Read, Write, Edit, Bash, etc.) just like normal Claude Code
- Communication between agents happens via **file I/O** (JSON traces/deltas)
- The orchestrator persists across loops, maintaining state and coordination

## Advanced: Creating Your Own Tasks

Create a custom task file for your domain:

```jsonl
{"task": "Optimize the database query in user_service.py", "context": "Focus on N+1 query issues"}
{"task": "Add OpenAPI spec for all REST endpoints", "context": "Use existing schema definitions"}
{"task": "Refactor error handling to use custom exception hierarchy", "context": "Maintain backward compatibility"}
```

Then run:
```bash
> /ace batch my-tasks.jsonl --loops 2
```

The playbook will evolve heuristics specific to your codebase and patterns.

## Troubleshooting

**Subagent returns invalid JSON**
- The orchestrator should handle this gracefully and skip that iteration
- Check `.claude/playbook/traces/` for the raw output
- Adjust the role prompt to emphasize JSON-only output

**Playbook grows too large**
- Manually deprecate low-utility bullets (low `helpful` count)
- Merge semantically similar bullets
- Consider setting a max bullet count in curator.txt

**Generator ignores playbook bullets**
- Increase emphasis in generator.txt ("binding heuristics")
- Add explicit examples of referencing bullets in actions
- Review traces to see if bullets are actually being referenced

**Loop runs too slowly**
- Subagents have overhead; batch mode is more efficient than single tasks
- Consider reducing iterations or task count for faster feedback
- Check if Generator tasks are overly complex

## References

- [Agentic Context Engineering Concept](https://example.com/ace-paper) (replace with actual link)
- [Claude Code Documentation](https://docs.claude.com/claude-code)
- [Task Tool for Subagents](https://docs.claude.com/claude-code/tools/task)

## What's New in This Version

### v1.1.0 - Enhanced Readability & Git Integration

**Human-Readable Format:**
- Playbook now uses JSON5 with inline comments
- Markdown trace summaries alongside JSON
- Visual diff indicators (+, ~, -, ↑)
- Rich progress output with emojis

**Git Integration:**
- Auto-commit after each task
- Auto-push to remote (if configured)
- Descriptive commit messages with change summary
- Full version control of playbook evolution

**Enhanced Tracking:**
- Bullet metadata (created_at, last_triggered)
- Overall playbook statistics
- Performance rankings
- Trace examples per bullet

**Better UX:**
- Visual progress indicators (✓, ⚠, etc.)
- Summary stats after batch runs
- Top performer lists
- Clear error messages

## FAQ

**Q: Do I need to manually edit the playbook?**
A: No! The playbook evolves automatically through the ACE loop. However, you can manually seed it with domain-specific heuristics if desired.

**Q: What if git push fails?**
A: ACE will warn but continue. Your commits are still saved locally. Configure remote with `git remote add origin <url>`.

**Q: Can I disable git integration?**
A: Yes, just don't initialize git in your project. ACE will skip git operations gracefully.

**Q: How do I view traces?**
A: Check `.claude/playbook/traces/`. The `.md` files are human-readable summaries you can open in any text editor.

**Q: Can I convert this to a global Claude Code skill?**
A: Yes! The current structure is per-project, but you could create a skill that references these prompt templates globally. See Claude Code skills documentation.

**Q: What's the difference between helpful and harmful counters?**
A: The Reflector increments `helpful` when a bullet contributed to success, `harmful` when it caused issues. Use these to identify which heuristics work.

**Q: How often should I prune the playbook?**
A: Review every ~20 tasks. Remove bullets with low helpful counts or high harmful counts.

## Contributing

This is an experimental framework. Contributions welcome:
- Improved prompt templates
- Additional utility functions
- Playbook visualization tools
- Analysis scripts for trace data

## License

This scaffold is provided as-is for experimentation. Adapt freely to your needs.
